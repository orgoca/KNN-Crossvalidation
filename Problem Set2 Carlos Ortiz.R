#Carlos Ortiz-Gomez
#Student ID 91351021
#Exam ID 6342

##Problem set 2

###DATA QUESTIONS

#Set up the environment

install.packages("ISLR")
install.packages("class")
install.packages("FNN")
library (ISLR)
library(class)
library(FNN)
data(Hitters)
summary(Hitters)
head(Hitters)

##1.How many observations have missing values for at least one feature?

sum(is.na(Hitters))

##59 observations have missing values

Hittersa <- na.omit(Hitters)

dim(Hittersa)

##2.Which variables are categorical variables? How many classes do each of these categorical
##variables have??

#League, Division and NewLeague are categorical, each with two categorical variables. Detail following:
#$ League   : Factor w/ 2 levels "A","N"
#$ Division : Factor w/ 2 levels "E","W"
#$ NewLeague: Factor w/ 2 levels "A","N"

str(Hittersa)

##3.Convert the categorical variables to indicator variables (also called "dummy" variables) with the same 
##variable names and run a linear regression. What is the adjusted R2? 

#Create dummy variables for League, Division and New League

Hittersa$DummyLeague <-ifelse((Hittersa$League== "A"),1,0)

Hittersa$DummyDivision <-ifelse((Hittersa$Division== "E"),1,0)

Hittersa$DummyNewLeague <-ifelse((Hittersa$NewLeague== "A"),1,0)

Hittersa$League <- NULL

Hittersa$Division <- NULL

Hittersa$NewLeague <- NULL

formulaa <- paste(colnames(Hittersa[,-3]), collapse = " + ")
lmformulaa <- paste("HmRun", formulaa, sep = " ~ ")

print(lmformulaa)

lregmode1 <- lm(as.formula(lmformulaa), Hittersa)
summary (lregmode1)

#My adjusted R2 value is 0.86 (rounding to two digits even though this problem set does not require it. I lost 
#a lot of points for that in my last problem set!)

##4.Run ridge regression with cross-validation using the canned function cv.glmnet from the package glmnet. 
##You can use the ?? sequence generated by cv.glment (you do not need to provide your own ?? sequence). In order 
##to receive credit for this question, make the line immediately preceding this command say set.seed(222) and 
##run the two lines together. Please report all numbers by rounding to three decimal places. 

install.packages("glmnet")

library(glmnet)

set.seed(222)
ridgeHmruns       <- cv.glmnet(x = as.matrix(Hittersa[,-3]),
                             y = as.numeric(Hittersa[,3]),
                             alpha = 0)

#Create answers matrix for question 4 index a through d

CVmatrix <- matrix(0, ncol=4, nrow=1)

#4.a.Which ?? had the lowest mean cross-validation error?

which(ridgeHmruns$lambda== ridgeHmruns$lambda.min)

CVmatrix[,1] <- round(ridgeHmruns$lambda.min, digits = 3)

##Lambda index No. 99 with a value of 0.814 

#4.b.What was the cross-validation error?

CVmatrix[,2] <- round(ridgeHmruns$cvm[which(ridgeHmruns$lambda == ridgeHmruns$lambda.min)], digits = 3)

#Lambda index 99 had a cvm (Cross Validation Error) of 15.216

#4.c.What was the standard error of the mean cross-validation error for this value of ???

CVmatrix[,3] <- round(ridgeHmruns$cvsd[which(ridgeHmruns$lambda == ridgeHmruns$lambda.min)], digits = 3)

#Standard error for this Lambda index 99 is 1.18

#4.d.What was the largest value of ?? whose mean cross validation error was within one standard 
#deviation of the lowest cross-validation error?

CVmatrix[,4] <- round(ridgeHmruns$lambda.1se, digits = 3)

#the largest value of ?? whose mean cross validation error was within one standard deviation of the 
#lowest cross-validation error is 1.182

#Plot answer matrix for question 4 index a through d

#name columns for my answer matrix

colnames(CVmatrix) <- c("4.a. Lambda index 99", 
                        "4.b. CVE for lambda index 99",
                        "4.c. SE of CVE for lambda index 99",
                        "4.d. Largest lambda 1sd from lambda index 99")

rownames(CVmatrix) <- c("Obtained values")

#view my answer matrix

View(CVmatrix)

#5.Using the same data, implement your own 5-fold cross-validation routine for KNN for k = 1, ..., 100 
#(e.g. write the cross-validation routine yourself rather than using a canned package). Include the 
#snippet of code you wrote here. It should not exceed 20 lines. Which k is best according to CV?

###Cross validation routine begins### 

CVKNN <- function(data_x, data_y, k_seq, kfolds) {
  
  fold_ids      <- rep(seq(kfolds), ceiling(nrow(data_x) / kfolds))
  
  fold_ids      <- fold_ids[1:nrow(data_x)]
  
  fold_ids      <- sample(fold_ids, length(fold_ids))
  
  CVerr  <- matrix(0, nrow = length(k_seq), ncol = kfolds)
 
  for (k in k_seq) {

    for (fold in 1:kfolds) {
      
            knn_fold_model    <- knn.reg(train = data_x[which(fold_ids != fold),],
                            
                                   test = data_x[which(fold_ids == fold),],
                               
                                   data_y[which(fold_ids != fold)], k = k)
      
      CVerr[k,fold]  <- mean((knn_fold_model$pred -
                                      
                                 data_y[which(fold_ids == fold)])^2) }  }
   
   return(CVerr) }

KNNCVerr          <- CVKNN(data_x = Hittersa[,-3],
                                              data_y = Hittersa[,3],
                                              k_seq = seq(100),
                                              kfolds = 5)

###Cross validation routine ends (empty lines added for ease of reading but used only 17 lines of code) ###

View(KNNCVerr)

print(KNNCVerr)

CVMSEplotdata <- rowMeans(KNNCVerr)

#6.Plot mean cross-validation MSE as a function of k. Label the y-axis "Mean CV MSE"and the x-axis "k".

plot(CVMSEplotdata, main="Mean Cross-Validation MSE as a function of k", type = "b", xlab = "k", ylab = "Mean CV MSE")



